{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np63oMwDmPrd"
      },
      "source": [
        "# Melanoma Dermoscopic Prognosis - Colab Training Notebook\n",
        "\n",
        "This notebook sets up the environment, downloads data from Google Drive, and trains the model using `main.py`.\n",
        "\n",
        "**Note:** The model uses image-only input (dermoscopic images). Clinical features are not required.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMz6tSSFmPre"
      },
      "source": [
        "## Step 1: Clone Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlhzaHzDmPrf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Clone the repository\n",
        "repo_url = \"https://github.com/Salahuddin-quadri/Melanoma-Dermoscopic-Prognosis.git\"\n",
        "repo_name = \"Melanoma-Dermoscopic-Prognosis\"\n",
        "\n",
        "# Check if we're already in the repo directory\n",
        "if os.path.exists(\"src/main.py\"):\n",
        "    print(\"Already in repository directory. Skipping clone.\")\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "elif os.path.exists(repo_name):\n",
        "    print(f\"Repository {repo_name} already exists. Changing to it.\")\n",
        "    os.chdir(repo_name)\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "else:\n",
        "    # Clone the repository\n",
        "    get_ipython().system(f'git clone {repo_url}')\n",
        "    os.chdir(repo_name)\n",
        "    print(f\"Cloned and changed to: {os.getcwd()}\")\n",
        "\n",
        "# Verify we're in the right place\n",
        "assert os.path.exists(\"src/main.py\"), \"src/main.py not found! Check repository structure.\"\n",
        "print(\"✓ Repository setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X831NdtSmPrg"
      },
      "source": [
        "## Step 2: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5dtCBpmmPrg"
      },
      "outputs": [],
      "source": [
        "# Install PyTorch with CUDA support\n",
        "!pip install torch==2.3.1 torchvision==0.18.1 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install numpy==1.26.4 pandas==2.2.2 scikit-learn==1.4.2 scipy==1.11.4\n",
        "!pip install matplotlib==3.8.4 seaborn==0.13.2 opencv-python==4.10.0.84 Pillow==10.4.0\n",
        "!pip install tqdm==4.66.4 ipywidgets==8.1.3 imbalanced-learn==0.12.3\n",
        "!pip install gdown\n",
        "\n",
        "print(\"✓ Dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG9n62JvmPrh"
      },
      "source": [
        "## Step 3: Mount Google Drive and Download Data\n",
        "\n",
        "**Important:** The data files are large (~1GB). We'll mount Google Drive and download directly from the shared folders.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1EUX0TGmPrh"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"✓ Google Drive mounted successfully!\")\n",
        "print(\"Your Drive is now accessible at /content/drive/MyDrive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDa-QzWEmPrh"
      },
      "source": [
        "### Download Data Folder from Google Drive\n",
        "\n",
        "The data folder contains:\n",
        "- `images/` - dermoscopic images\n",
        "- `merged_dataset.csv` - metadata CSV\n",
        "- `meta_data.csv` - additional metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYvp9NulmPri"
      },
      "outputs": [],
      "source": [
        "# Download the file from Google Drive\n",
        "file_id = \"1LCbiPcQXJperjrOhG4Xb947rkCiJPDRh\"\n",
        "output_filename = \"downloaded_file.zip\"\n",
        "\n",
        "!gdown {file_id} -O {output_filename}\n",
        "\n",
        "# Unzip only the 'data/' folder into the current directory\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile(output_filename, 'r') as zip_ref:\n",
        "    members = [m for m in zip_ref.namelist() if m.startswith(\"data/\")]\n",
        "    zip_ref.extractall(members=members)\n",
        "\n",
        "print(\"✓ 'data/' folder extracted to current directory.\")\n",
        "print(\"\\nExtracted contents of 'data/':\")\n",
        "!ls -la data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDajblDgmPri"
      },
      "source": [
        "### Download DINO v3 Pretrained Model from Google Drive\n",
        "\n",
        "The dino_v3 folder contains the pretrained checkpoint needed for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI2Pi1zqmPri"
      },
      "outputs": [],
      "source": [
        "# Google Drive folder ID for dino_v3 model\n",
        "dino_folder_id = \"1wlozH7SchoPkAgsDpn-DyBN-F2Ea8hmP\"\n",
        "\n",
        "# Create dino_v3 directory\n",
        "dino_dest = \"dino_v3\"\n",
        "os.makedirs(dino_dest, exist_ok=True)\n",
        "\n",
        "print(f\"Downloading dino_v3 folder (ID: {dino_folder_id})...\")\n",
        "print(\"This may take a while as the folder is large...\")\n",
        "\n",
        "# Use gdown to download the entire folder\n",
        "get_ipython().system(f'gdown --folder https://drive.google.com/drive/folders/{dino_folder_id} -O {dino_dest} --remaining-ok')\n",
        "\n",
        "print(\"\\n✓ DINO v3 model download complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXNV-HSTmPri"
      },
      "source": [
        "### Verify Downloaded Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UL4f_NBmPrj"
      },
      "outputs": [],
      "source": [
        "# Verify data files\n",
        "data_dir = Path(\"data\")\n",
        "print(\"=\" * 60)\n",
        "print(\"DATA FOLDER VERIFICATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if data_dir.exists():\n",
        "    # Calculate total size\n",
        "    total_size_mb = sum(f.stat().st_size for f in data_dir.rglob('*') if f.is_file()) / (1024 * 1024)\n",
        "    print(f\"Total size: {total_size_mb:.2f} MB\")\n",
        "    print(f\"\\nContents:\")\n",
        "\n",
        "    # Check for required files\n",
        "    required_files = [\"merged_dataset.csv\", \"meta_data.csv\"]\n",
        "    for file in required_files:\n",
        "        file_path = data_dir / file\n",
        "        if file_path.exists():\n",
        "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
        "            print(f\"  ✓ {file} ({size_mb:.2f} MB)\")\n",
        "        else:\n",
        "            print(f\"  ✗ Missing: {file}\")\n",
        "\n",
        "    # Check for images folder\n",
        "    images_dir = data_dir / \"images\"\n",
        "    if images_dir.exists():\n",
        "        num_images = len([f for f in images_dir.rglob(\"*\") if f.is_file()])\n",
        "        images_size_mb = sum(f.stat().st_size for f in images_dir.rglob(\"*\") if f.is_file()) / (1024 * 1024)\n",
        "        print(f\"  ✓ images/ folder ({num_images} files, {images_size_mb:.2f} MB)\")\n",
        "    else:\n",
        "        print(f\"  ✗ Missing: images/ folder\")\n",
        "else:\n",
        "    print(\"✗ Data directory not found!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DINO_V3 FOLDER VERIFICATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify dino_v3 files\n",
        "dino_dir = Path(\"dino_v3\")\n",
        "if dino_dir.exists():\n",
        "    total_size_mb = sum(f.stat().st_size for f in dino_dir.rglob('*') if f.is_file()) / (1024 * 1024)\n",
        "    print(f\"Total size: {total_size_mb:.2f} MB\")\n",
        "    print(f\"\\nContents:\")\n",
        "\n",
        "    # Check for checkpoint\n",
        "    checkpoint_path = dino_dir / \"outputs_dino\" / \"checkpoints\" / \"best.pt\"\n",
        "    if checkpoint_path.exists():\n",
        "        size_mb = checkpoint_path.stat().st_size / (1024 * 1024)\n",
        "        print(f\"  ✓ {checkpoint_path.relative_to(dino_dir)} ({size_mb:.2f} MB)\")\n",
        "    else:\n",
        "        # Try alternative paths\n",
        "        checkpoints = list(dino_dir.rglob(\"*.pt\"))\n",
        "        if checkpoints:\n",
        "            for ckpt in checkpoints:\n",
        "                size_mb = ckpt.stat().st_size / (1024 * 1024)\n",
        "                print(f\"  ✓ {ckpt.relative_to(dino_dir)} ({size_mb:.2f} MB)\")\n",
        "        else:\n",
        "            print(f\"  ✗ No checkpoint files (.pt) found\")\n",
        "\n",
        "    # List all files\n",
        "    print(f\"\\nAll files in dino_v3:\")\n",
        "    for item in sorted(dino_dir.rglob(\"*\")):\n",
        "        if item.is_file():\n",
        "            size_mb = item.stat().st_size / (1024 * 1024)\n",
        "            print(f\"  {item.relative_to(dino_dir)} ({size_mb:.2f} MB)\")\n",
        "else:\n",
        "    print(\"✗ dino_v3 directory not found!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z4U2FPqmPrj"
      },
      "source": [
        "## Step 4: Verify Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7271UdvmPrj"
      },
      "outputs": [],
      "source": [
        "# Check Python version\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Check PyTorch\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "\n",
        "# Check repository structure\n",
        "print(\"\\nRepository structure:\")\n",
        "print(f\"  Current directory: {os.getcwd()}\")\n",
        "print(f\"  src/main.py exists: {os.path.exists('src/main.py')}\")\n",
        "print(f\"  requirements.txt exists: {os.path.exists('requirements.txt')}\")\n",
        "\n",
        "print(\"\\n✓ Setup verification complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzcoRcCOmPrj"
      },
      "source": [
        "## Step 5: Training Configuration\n",
        "\n",
        "Configure your training parameters here. Adjust as needed.\n",
        "\n",
        "**Model Architecture:** The model takes only dermoscopic images as input (no clinical features).\n",
        "- DINO model: Uses Vision Transformer (ViT) backbone with domain-specific pretraining\n",
        "- ResNet model: Uses ResNet50 backbone with ImageNet pretraining\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilb7l51mmPrj"
      },
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "# Note: Model takes only images as input (no clinical features)\n",
        "config = {\n",
        "    \"metadata_path\": \"data/meta_data.csv\",\n",
        "    \"image_dir\": \"data/images\",\n",
        "    \"mode\": \"train\",\n",
        "    \"model_type\": \"dino\",  # \"dino\" or \"resnet\"\n",
        "    \"epochs\": 200,\n",
        "    \"batch_size\": 32,\n",
        "    \"image_size\": [224,224],\n",
        "    \"output_dir\": \"outputs\",\n",
        "    \"task\": \"classification\",  # \"classification\" or \"regression\" (used when multitask=False)\n",
        "    \"multitask\": True,  # Set to True for dual-head (classification + regression)\n",
        "    \"loss_alpha\": 0.5,  # Weight for classification loss in multitask (0-1)\n",
        "    \"cls_loss_type\": \"weighted_bce\",  # \"bce\", \"weighted_bce\", or \"focal\"\n",
        "    \"focal_gamma\": 2.0,  # For focal loss (used when cls_loss_type=\"focal\")\n",
        "    \"freeze_backbone_layers\": 7,  # Number of ViT layers to freeze (0 = all trainable)\n",
        "    \"val_size\": 0.15,\n",
        "    \"test_size\": 0.15,\n",
        "    \"device\": \"auto\",  # \"cuda\", \"cpu\", or \"auto\"\n",
        "}\n",
        "\n",
        "# Set DINO checkpoint path\n",
        "# Try to find the checkpoint automatically\n",
        "dino_checkpoint_candidates = [\n",
        "    \"dino_v3/outputs_dino/checkpoints/best.pt\",\n",
        "    \"dino_v3/checkpoints/best.pt\",\n",
        "]\n",
        "\n",
        "dino_checkpoint = None\n",
        "for candidate in dino_checkpoint_candidates:\n",
        "    if os.path.exists(candidate):\n",
        "        dino_checkpoint = candidate\n",
        "        break\n",
        "\n",
        "if dino_checkpoint:\n",
        "    config[\"dino_checkpoint\"] = dino_checkpoint\n",
        "    print(f\"✓ Found DINO checkpoint: {dino_checkpoint}\")\n",
        "else:\n",
        "    print(\"⚠ No DINO checkpoint found. Will use ImageNet pretrained weights.\")\n",
        "    # Don't set dino_checkpoint if not found\n",
        "\n",
        "print(\"\\nTraining configuration:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlhh_nAImPrj"
      },
      "source": [
        "## Step 6: Run Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvNVwUlQmPrj"
      },
      "outputs": [],
      "source": [
        "# Build command arguments\n",
        "args_list = []\n",
        "for key, value in config.items():\n",
        "    if value is not None and value != \"\":\n",
        "        if isinstance(value, bool):\n",
        "            if value:\n",
        "                args_list.append(f\"--{key}\")\n",
        "        elif isinstance(value, list):\n",
        "            args_list.append(f\"--{key}\")\n",
        "            args_list.extend([str(v) for v in value])\n",
        "        else:\n",
        "            args_list.append(f\"--{key}\")\n",
        "            args_list.append(str(value))\n",
        "\n",
        "# Convert to string\n",
        "args_str = \" \".join(args_list)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAINING COMMAND\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"python -m src.main {args_str}\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nStarting training...\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Khv4bfvLmPrk"
      },
      "outputs": [],
      "source": [
        "# Run training\n",
        "get_ipython().system(f'python -m src.main {args_str}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHcsOt0DmPrk"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWG5TX5xmPrk"
      },
      "outputs": [],
      "source": [
        "# List output files\n",
        "# Note: Training creates subdirectories train1, train2, etc. (YOLO-style organization)\n",
        "output_dir = Path(config[\"output_dir\"])\n",
        "if output_dir.exists():\n",
        "    print(f\"Output directory: {output_dir}\")\n",
        "    print(\"\\nContents:\")\n",
        "\n",
        "    # Find training run directories (train1, train2, etc.)\n",
        "    train_dirs = sorted([d for d in output_dir.iterdir() if d.is_dir() and d.name.startswith(\"train\")])\n",
        "\n",
        "    if train_dirs:\n",
        "        latest_train_dir = train_dirs[-1]\n",
        "        print(f\"\\nLatest training run: {latest_train_dir.name}\")\n",
        "\n",
        "        # List files in latest training run\n",
        "        for item in latest_train_dir.rglob(\"*\"):\n",
        "            if item.is_file():\n",
        "                size = item.stat().st_size / (1024 * 1024)  # Size in MB\n",
        "                print(f\"  {item.relative_to(output_dir)} ({size:.2f} MB)\")\n",
        "\n",
        "        # Check for checkpoints in latest training run\n",
        "        checkpoint_dir = latest_train_dir / \"checkpoints\"\n",
        "        if checkpoint_dir.exists():\n",
        "            print(f\"\\nCheckpoints in {latest_train_dir.name}:\")\n",
        "            for ckpt in checkpoint_dir.glob(\"*.pt\"):\n",
        "                size = ckpt.stat().st_size / (1024 * 1024)\n",
        "                print(f\"  ✓ {ckpt.name} ({size:.2f} MB)\")\n",
        "        else:\n",
        "            print(f\"\\n⚠ No checkpoints directory found in {latest_train_dir.name}\")\n",
        "    else:\n",
        "        # Fallback: list all files directly\n",
        "        for item in output_dir.rglob(\"*\"):\n",
        "            if item.is_file():\n",
        "                size = item.stat().st_size / (1024 * 1024)  # Size in MB\n",
        "                print(f\"  {item.relative_to(output_dir)} ({size:.2f} MB)\")\n",
        "else:\n",
        "    print(f\"⚠ Output directory {output_dir} not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnostic & robust import helper for your repo\n",
        "import os, sys, importlib, traceback\n",
        "from pathlib import Path\n",
        "PROJECT_DIR = \"/content/Melanoma-Dermoscopic-Prognosis\"   # adjust only if you cloned elsewhere\n",
        "print(\"PROJECT_DIR exists:\", os.path.exists(PROJECT_DIR))\n",
        "print(\"CWD:\", os.getcwd())\n",
        "\n",
        "# show top-level contents\n",
        "print(\"\\nTop-level files/folders in PROJECT_DIR:\")\n",
        "for p in sorted(os.listdir(PROJECT_DIR)):\n",
        "    print(\" -\", p)\n",
        "\n",
        "# make sure PROJECT_DIR is on sys.path\n",
        "if PROJECT_DIR not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_DIR)\n",
        "    print(\"\\nInserted PROJECT_DIR into sys.path\")\n",
        "\n",
        "print(\"\\nsys.path head:\")\n",
        "for i, p in enumerate(sys.path[:6]):\n",
        "    print(f\" [{i}] {p}\")\n",
        "\n",
        "# show src folder contents if present\n",
        "src_dir = Path(PROJECT_DIR) / \"src\"\n",
        "print(\"\\nsrc exists:\", src_dir.exists())\n",
        "if src_dir.exists():\n",
        "    print(\"src contents:\")\n",
        "    for p in sorted(os.listdir(src_dir)):\n",
        "        print(\"  -\", p)\n",
        "    # if models is a directory, show its files too\n",
        "    models_dir = src_dir / \"models\"\n",
        "    print(\"src/models exists:\", models_dir.exists())\n",
        "    if models_dir.exists():\n",
        "        print(\"src/models contents:\")\n",
        "        for p in sorted(os.listdir(models_dir)):\n",
        "            print(\"    -\", p)\n",
        "\n",
        "# Try the normal import\n",
        "print(\"\\nAttempting: from src.models import create_dino_hybrid_model\")\n",
        "try:\n",
        "    from src.models import create_dino_hybrid_model\n",
        "    print(\"✅ Import succeeded. create_dino_hybrid_model:\", create_dino_hybrid_model)\n",
        "except Exception as e:\n",
        "    print(\"❌ Import failed. Traceback:\\n\")\n",
        "    traceback.print_exc()\n",
        "\n",
        "    # Fallback: attempt to locate the file that defines the function and import it directly\n",
        "    # Common candidate files:\n",
        "    candidates = [\n",
        "        src_dir / \"models\" / \"__init__.py\",\n",
        "        src_dir / \"models\" / \"dino_hybrid.py\",\n",
        "        src_dir / \"models\" / \"factory.py\",\n",
        "        src_dir / \"models.py\"\n",
        "    ]\n",
        "    print(\"\\nLooking for candidate files to import directly:\")\n",
        "    for c in candidates:\n",
        "        print(\" -\", c, \"exists:\", c.exists())\n",
        "\n",
        "    # Try to find any .py under src/models that contains the symbol name\n",
        "    found_path = None\n",
        "    if (src_dir / \"models\").exists():\n",
        "        for p in (src_dir / \"models\").rglob(\"*.py\"):\n",
        "            try:\n",
        "                txt = p.read_text(errors=\"ignore\")\n",
        "                if \"create_dino_hybrid_model\" in txt or \"class DinoHybrid\" in txt:\n",
        "                    found_path = p\n",
        "                    break\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    if found_path is None:\n",
        "        # also try src root\n",
        "        for p in src_dir.rglob(\"*.py\"):\n",
        "            try:\n",
        "                txt = p.read_text(errors=\"ignore\")\n",
        "                if \"create_dino_hybrid_model\" in txt or \"class DinoHybrid\" in txt:\n",
        "                    found_path = p\n",
        "                    break\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    if found_path:\n",
        "        print(\"\\nFound candidate file defining the model function/class:\", found_path)\n",
        "        # Import directly from path\n",
        "        try:\n",
        "            import importlib.util\n",
        "            spec = importlib.util.spec_from_file_location(\"custom_models_module\", str(found_path))\n",
        "            mod = importlib.util.module_from_spec(spec)\n",
        "            spec.loader.exec_module(mod)\n",
        "            # try to get function\n",
        "            if hasattr(mod, \"create_dino_hybrid_model\"):\n",
        "                create_dino_hybrid_model = getattr(mod, \"create_dino_hybrid_model\")\n",
        "                print(\"✅ Loaded create_dino_hybrid_model from file:\", found_path)\n",
        "            else:\n",
        "                print(\"⚠ Found file but it does not contain create_dino_hybrid_model. Available symbols:\", [n for n in dir(mod) if not n.startswith(\"_\")][:50])\n",
        "        except Exception:\n",
        "            print(\"❌ Failed to import directly from file. Traceback:\")\n",
        "            traceback.print_exc()\n",
        "    else:\n",
        "        print(\"\\nCould not find a candidate file that defines create_dino_hybrid_model automatically.\")\n",
        "        print(\"Please check where the function is defined in your repo and run an import or share the listing above.\")\n",
        "\n",
        "print(\"\\nIf import still fails, paste the output of this cell here and I'll give the exact next command.\")\n"
      ],
      "metadata": {
        "id": "XDZ0pIQlo4CT",
        "outputId": "79e3091f-1ff9-44ad-8580-8b2a33492dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROJECT_DIR exists: True\n",
            "CWD: /content/Melanoma-Dermoscopic-Prognosis\n",
            "\n",
            "Top-level files/folders in PROJECT_DIR:\n",
            " - .git\n",
            " - .gitattributes\n",
            " - .gitignore\n",
            " - CLASS_IMBALANCE_SOLUTIONS.md\n",
            " - LICENSE\n",
            " - README.md\n",
            " - data\n",
            " - dino_v3\n",
            " - error.txt\n",
            " - notebooks\n",
            " - plot_training_log.py\n",
            " - project_paper_context.txt\n",
            " - related_work_raw_notes.txt\n",
            " - requirements.txt\n",
            " - src\n",
            " - training.md\n",
            "\n",
            "sys.path head:\n",
            " [0] /content/Melanoma-Dermoscopic-Prognosis\n",
            " [1] /content\n",
            " [2] /env/python\n",
            " [3] /usr/lib/python312.zip\n",
            " [4] /usr/lib/python3.12\n",
            " [5] /usr/lib/python3.12/lib-dynload\n",
            "\n",
            "src exists: True\n",
            "src contents:\n",
            "  - __init__.py\n",
            "  - evaluate.py\n",
            "  - main.py\n",
            "  - models\n",
            "  - train.py\n",
            "  - utils\n",
            "src/models exists: True\n",
            "src/models contents:\n",
            "    - __init__.py\n",
            "    - dino_hybrid.py\n",
            "    - fusion.py\n",
            "    - resnet50_hybrid.py\n",
            "\n",
            "Attempting: from src.models import create_dino_hybrid_model\n",
            "❌ Import failed. Traceback:\n",
            "\n",
            "\n",
            "Looking for candidate files to import directly:\n",
            " - /content/Melanoma-Dermoscopic-Prognosis/src/models/__init__.py exists: True\n",
            " - /content/Melanoma-Dermoscopic-Prognosis/src/models/dino_hybrid.py exists: True\n",
            " - /content/Melanoma-Dermoscopic-Prognosis/src/models/factory.py exists: False\n",
            " - /content/Melanoma-Dermoscopic-Prognosis/src/models.py exists: False\n",
            "\n",
            "Found candidate file defining the model function/class: /content/Melanoma-Dermoscopic-Prognosis/src/models/dino_hybrid.py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2528247755.py\", line 40, in <cell line: 0>\n",
            "    from src.models import create_dino_hybrid_model\n",
            "ModuleNotFoundError: No module named 'src'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded create_dino_hybrid_model from file: /content/Melanoma-Dermoscopic-Prognosis/src/models/dino_hybrid.py\n",
            "\n",
            "If import still fails, paste the output of this cell here and I'll give the exact next command.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Single-run cell: robust import + extract layers 13,14,15 + show overlays ===\n",
        "import os, sys, math, json, traceback\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch, torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps, ImageEnhance, ImageDraw, ImageFont\n",
        "\n",
        "PROJECT_DIR = \"/content/Melanoma-Dermoscopic-Prognosis\"\n",
        "OUT_DIR = Path(\"/content/feature_outputs\")\n",
        "ATT_DIR = OUT_DIR / \"attention_fixed\"\n",
        "OVER_DIR = OUT_DIR / \"overlays\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ATT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OVER_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Replace this with a real dermoscopic image path you uploaded to Colab\n",
        "IMAGE_PATH = \"/content/sample_lesion.png\"   # <-- change to your uploaded image path\n",
        "\n",
        "# Ensure repo on sys.path\n",
        "if PROJECT_DIR not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_DIR)\n",
        "\n",
        "# Try normal import, else fallback to direct file import\n",
        "create_dino_hybrid_model = None\n",
        "try:\n",
        "    from src.models import create_dino_hybrid_model as _factory\n",
        "    create_dino_hybrid_model = _factory\n",
        "    print(\"Imported create_dino_hybrid_model via package import.\")\n",
        "except Exception as e:\n",
        "    print(\"Package import failed. Falling back to loading from file...\")\n",
        "    # Path we discovered earlier\n",
        "    fallback_path = Path(PROJECT_DIR) / \"src\" / \"models\" / \"dino_hybrid.py\"\n",
        "    print(\"Attempting to load from:\", fallback_path)\n",
        "    import importlib.util\n",
        "    spec = importlib.util.spec_from_file_location(\"dino_hybrid_mod\", str(fallback_path))\n",
        "    mod = importlib.util.module_from_spec(spec)\n",
        "    spec.loader.exec_module(mod)\n",
        "    # The factory may be defined at module scope or returned by a helper — try to get it\n",
        "    if hasattr(mod, \"create_dino_hybrid_model\"):\n",
        "        create_dino_hybrid_model = getattr(mod, \"create_dino_hybrid_model\")\n",
        "        print(\"Loaded create_dino_hybrid_model from file.\")\n",
        "    else:\n",
        "        # if not present, show available names for debugging\n",
        "        print(\"Fallback file loaded but factory not found. Available symbols:\", [n for n in dir(mod) if not n.startswith(\"_\")][:200])\n",
        "        raise RuntimeError(\"create_dino_hybrid_model not found in fallback module.\")\n",
        "\n",
        "# Create the model using the correct signature\n",
        "model = create_dino_hybrid_model(\n",
        "    task=\"classification\",\n",
        "    multitask=False,\n",
        "    arch=\"vit_b_16\",\n",
        "    pretrained=False,\n",
        "    dino_checkpoint=None,\n",
        "    use_tokens=False,\n",
        "    hidden_dim=256,\n",
        "    dropout=0.1,\n",
        "    freeze_backbone_layers=0\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device).eval()\n",
        "print(\"Model ready on\", device)\n",
        "\n",
        "# Locate backbone and encoder layers\n",
        "backbone = None\n",
        "if hasattr(model, \"backbone\") and hasattr(model.backbone, \"vit\"):\n",
        "    backbone = model.backbone.vit\n",
        "elif hasattr(model, \"vit\"):\n",
        "    backbone = model.vit\n",
        "elif hasattr(model, \"backbone\") and hasattr(model.backbone, \"vit\"):\n",
        "    backbone = model.backbone.vit\n",
        "\n",
        "if backbone is None:\n",
        "    raise RuntimeError(\"Backbone not found in model.\")\n",
        "\n",
        "# find encoder layers container\n",
        "if hasattr(backbone, \"encoder\") and hasattr(backbone.encoder, \"layers\"):\n",
        "    encoder_layers = backbone.encoder.layers\n",
        "elif hasattr(backbone, \"blocks\"):\n",
        "    encoder_layers = backbone.blocks\n",
        "else:\n",
        "    encoder_layers = None\n",
        "    for n in dir(backbone):\n",
        "        a = getattr(backbone, n)\n",
        "        if isinstance(a, torch.nn.ModuleList):\n",
        "            encoder_layers = a\n",
        "            break\n",
        "if encoder_layers is None:\n",
        "    raise RuntimeError(\"Could not locate encoder layers container.\")\n",
        "\n",
        "num_layers = len(encoder_layers)\n",
        "print(\"Encoder layers detected:\", num_layers)\n",
        "\n",
        "# request layers 13,14,15\n",
        "requested = [13,14,15]\n",
        "selected = [i for i in requested if i < num_layers]\n",
        "if not selected:\n",
        "    raise RuntimeError(f\"Model has {num_layers} layers; none of {requested} are valid. Choose indices < {num_layers}.\")\n",
        "print(\"Using layers:\", selected)\n",
        "\n",
        "# Freeze only selected layers\n",
        "for idx in selected:\n",
        "    for p in encoder_layers[idx].parameters():\n",
        "        p.requires_grad = False\n",
        "print(\"Frozen layers:\", selected)\n",
        "\n",
        "# Capture inputs to these encoder blocks\n",
        "inputs_store = {}\n",
        "hooks = []\n",
        "def make_hook(i):\n",
        "    def hook(module, inp, out):\n",
        "        try:\n",
        "            inputs_store[f\"layer_{i}\"] = inp[0].detach().cpu()\n",
        "        except Exception as exc:\n",
        "            print(\"Hook store failed for\", i, exc)\n",
        "    return hook\n",
        "\n",
        "for idx in selected:\n",
        "    hooks.append(encoder_layers[idx].register_forward_hook(make_hook(idx)))\n",
        "    print(\"Attached hook to layer\", idx)\n",
        "\n",
        "# Prepare input\n",
        "from torchvision import transforms\n",
        "if os.path.exists(IMAGE_PATH):\n",
        "    pil = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
        "    tf = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(),\n",
        "                             transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])])\n",
        "    img = tf(pil).unsqueeze(0).to(device)\n",
        "    print(\"Using real image:\", IMAGE_PATH)\n",
        "else:\n",
        "    print(\"IMAGE_PATH not found; using random dummy tensor (results will be meaningless).\")\n",
        "    img = torch.randn(1,3,224,224).to(device)\n",
        "\n",
        "# Forward pass\n",
        "try:\n",
        "    _ = model(img)\n",
        "    print(\"Forward pass complete; captured keys:\", list(inputs_store.keys()))\n",
        "except Exception as e:\n",
        "    # try backbone forward_features as fallback\n",
        "    try:\n",
        "        if hasattr(backbone, \"forward_features\"):\n",
        "            _ = backbone.forward_features(img)\n",
        "            print(\"Backbone forward_features executed.\")\n",
        "    except Exception as e2:\n",
        "        print(\"Forward failed:\", e, e2)\n",
        "\n",
        "# remove hooks\n",
        "for h in hooks:\n",
        "    h.remove()\n",
        "\n",
        "# Compute attention from Q/K/V for each captured layer and save PNGs + overlays\n",
        "def reshape_for_heads(t, num_heads):\n",
        "    b,s,e = t.shape\n",
        "    head_dim = e // num_heads\n",
        "    return t.view(b, s, num_heads, head_dim).permute(0,2,1,3).contiguous()\n",
        "\n",
        "saved = []\n",
        "for k, x_cpu in inputs_store.items():\n",
        "    li = int(k.split(\"_\")[1])\n",
        "    x = x_cpu.to(device)\n",
        "    seq_len, batch, E = x.shape\n",
        "    att_mod = getattr(encoder_layers[li], \"self_attention\", None)\n",
        "    if att_mod is None:\n",
        "        print(\"No self_attention on layer\", li); continue\n",
        "    in_proj_w = att_mod.in_proj_weight.to(device); in_proj_b = att_mod.in_proj_bias.to(device)\n",
        "    embed_dim = att_mod.embed_dim; num_heads = att_mod.num_heads\n",
        "    x_b = x.permute(1,0,2).contiguous()\n",
        "    proj = F.linear(x_b, in_proj_w, in_proj_b)\n",
        "    q,k_,v = proj.split(embed_dim, dim=-1)\n",
        "    qh = reshape_for_heads(q, num_heads); kh = reshape_for_heads(k_, num_heads)\n",
        "    logits = torch.matmul(qh, kh.transpose(-2,-1)) / math.sqrt(embed_dim // num_heads)\n",
        "    attn = torch.softmax(logits, dim=-1).detach().cpu().numpy()  # (B, H, N, N)\n",
        "\n",
        "    # save raw\n",
        "    rawp = OUT_DIR / f\"layer_{li}_attn_raw_computed.npy\"\n",
        "    np.save(rawp, attn); saved.append(str(rawp))\n",
        "\n",
        "    # avg and png\n",
        "    arr_heads = attn[0] if attn.ndim==4 else attn\n",
        "    H,N,_ = arr_heads.shape\n",
        "    patches = N-1\n",
        "    if patches > 0:\n",
        "        s = int(math.sqrt(patches))\n",
        "        if s*s == patches:\n",
        "            avg = arr_heads.mean(axis=0)\n",
        "            cls_avg = avg[0,1:]\n",
        "            cls_avg = cls_avg - cls_avg.min()\n",
        "            if cls_avg.max() > 0: cls_avg = cls_avg/cls_avg.max()\n",
        "            grid = cls_avg.reshape(s,s)\n",
        "            pngp = ATT_DIR / f\"layer_{li}_attn_avg_computed.png\"\n",
        "            plt.figure(figsize=(4,4)); plt.imshow(grid, cmap=\"inferno\"); plt.axis(\"off\")\n",
        "            plt.savefig(pngp, bbox_inches=\"tight\", pad_inches=0); plt.close()\n",
        "            saved.append(str(pngp))\n",
        "\n",
        "            # overlay with existing patch grid if available\n",
        "            patch_png = OUT_DIR / f\"layer_{li}_patch_grid.png\"\n",
        "            if patch_png.exists():\n",
        "                # create overlay\n",
        "                att_arr = (grid - grid.min())\n",
        "                if att_arr.max()>0: att_arr = att_arr/att_arr.max()\n",
        "                att_img = Image.fromarray((plt.get_cmap(\"inferno\")(att_arr)[:,:,:3]*255).astype('uint8')).convert(\"RGBA\")\n",
        "                alpha = Image.fromarray((att_arr*255).astype('uint8')).resize(att_img.size, Image.BILINEAR)\n",
        "                att_img.putalpha(alpha)\n",
        "                patch_img = Image.open(patch_png).convert(\"L\")\n",
        "                patch_rgb = Image.fromarray((plt.get_cmap(\"viridis\")((np.array(patch_img).astype(float)-patch_img.min())/(patch_img.max()-patch_img.min()+1e-9))[:,:,:3]*255).astype('uint8')).convert(\"RGBA\")\n",
        "                composite = Image.alpha_composite(patch_rgb, att_img)\n",
        "                draw = ImageDraw.Draw(composite)\n",
        "                try:\n",
        "                    font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 18)\n",
        "                except Exception:\n",
        "                    font = None\n",
        "                draw.rectangle([0,0, composite.size[0], 34], fill=(0,0,0,160))\n",
        "                draw.text((8,6), f\"Layer {li} — Attention avg overlay\", fill=(255,255,255,255), font=font)\n",
        "                overlayp = OVER_DIR / f\"layer_{li}_overlay.png\"\n",
        "                composite.save(overlayp)\n",
        "                saved.append(str(overlayp))\n",
        "        else:\n",
        "            print(f\"layer {li}: patches={patches} not square; skipping png\")\n",
        "    else:\n",
        "        print(f\"layer {li}: no patch tokens (N={N}) - skipping png\")\n",
        "\n",
        "# Show results\n",
        "print(\"Saved files:\", saved)\n",
        "print(\"\\nNow displaying overlays (if created):\")\n",
        "from IPython.display import Image, display\n",
        "for p in sorted(os.listdir(OVER_DIR)):\n",
        "    if p.endswith(\".png\"):\n",
        "        print(\"Showing:\", p)\n",
        "        display(Image(filename=str(OVER_DIR / p)))\n",
        "\n",
        "# End of cell\n"
      ],
      "metadata": {
        "id": "NZWB4BFBphHS",
        "outputId": "f40ddfe7-ed11-4c15-9861-cd3a8bba282a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported create_dino_hybrid_model via package import.\n",
            "Model ready on cpu\n",
            "Encoder layers detected: 12\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Model has 12 layers; none of [13, 14, 15] are valid. Choose indices < 12.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2778321125.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequested\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model has {num_layers} layers; none of {requested} are valid. Choose indices < {num_layers}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using layers:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Model has 12 layers; none of [13, 14, 15] are valid. Choose indices < 12."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust import cell (run once)\n",
        "import os, sys, importlib.util, traceback\n",
        "PROJECT_DIR = \"/content/Melanoma-Dermoscopic-Prognosis\"\n",
        "if PROJECT_DIR not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_DIR)\n",
        "\n",
        "try:\n",
        "    from src.models import create_dino_hybrid_model\n",
        "    print(\"Imported factory via package import.\")\n",
        "except Exception:\n",
        "    print(\"Package import failed; falling back to file import.\")\n",
        "    fallback = os.path.join(PROJECT_DIR, \"src\", \"models\", \"dino_hybrid.py\")\n",
        "    spec = importlib.util.spec_from_file_location(\"dino_hybrid_mod\", fallback)\n",
        "    mod = importlib.util.module_from_spec(spec)\n",
        "    spec.loader.exec_module(mod)\n",
        "    create_dino_hybrid_model = getattr(mod, \"create_dino_hybrid_model\")\n",
        "    print(\"Loaded factory from:\", fallback)\n",
        "\n",
        "# Create model (no pretrained to avoid downloads; set pretrained=True if you want)\n",
        "model = create_dino_hybrid_model(\n",
        "    task=\"classification\",\n",
        "    multitask=False,\n",
        "    arch=\"vit_b_16\",\n",
        "    pretrained=False,\n",
        "    dino_checkpoint=None,\n",
        "    use_tokens=False,\n",
        "    hidden_dim=256,\n",
        "    dropout=0.1,\n",
        "    freeze_backbone_layers=0\n",
        ")\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(\"Model created on\", device)\n",
        "# show encoder layer count (where they live may vary)\n",
        "backbone = model.backbone.vit if hasattr(model, \"backbone\") and hasattr(model.backbone, \"vit\") else (model.vit if hasattr(model, \"vit\") else getattr(model.backbone, \"vit\", None))\n",
        "if backbone is None:\n",
        "    raise RuntimeError(\"Couldn't find backbone.vit on the model.\")\n",
        "encoder_layers = backbone.encoder.layers if hasattr(backbone, \"encoder\") and hasattr(backbone.encoder, \"layers\") else (backbone.blocks if hasattr(backbone, \"blocks\") else None)\n",
        "print(\"Encoder layers container found:\", type(encoder_layers), \"count =\", len(encoder_layers))\n"
      ],
      "metadata": {
        "id": "9RQLTF4Aqiwo",
        "outputId": "fa18385f-5ea0-45d7-a3c9-f431d110b200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported factory via package import.\n",
            "Model created on cpu\n",
            "Encoder layers container found: <class 'torch.nn.modules.container.Sequential'> count = 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Append 3 encoder blocks to the ViT backbone\n",
        "import copy, torch, torch.nn as nn\n",
        "\n",
        "# encoder_layers must exist from previous cell\n",
        "num_existing = len(encoder_layers)\n",
        "print(\"Existing encoder layers:\", num_existing)\n",
        "\n",
        "# pick a source block to clone (use last block)\n",
        "src_idx = num_existing - 1\n",
        "src_block = encoder_layers[src_idx]\n",
        "print(\"Cloning block at index\", src_idx, \"type:\", type(src_block))\n",
        "\n",
        "# create 3 new blocks by deepcopy\n",
        "new_blocks = []\n",
        "for i in range(3):\n",
        "    b = copy.deepcopy(src_block)\n",
        "    # Re-initialize key submodules to avoid copying optimizer states or bn params\n",
        "    # For standard Transformer blocks, re-init linear layers and LayerNorms.\n",
        "    for mod in b.modules():\n",
        "        # reset linear layers' weights & biases and LayerNorm weights/biases\n",
        "        if isinstance(mod, nn.Linear):\n",
        "            nn.init.xavier_uniform_(mod.weight)\n",
        "            if mod.bias is not None:\n",
        "                nn.init.zeros_(mod.bias)\n",
        "        elif isinstance(mod, nn.LayerNorm):\n",
        "            if hasattr(mod, \"weight\"):\n",
        "                nn.init.ones_(mod.weight)\n",
        "            if hasattr(mod, \"bias\"):\n",
        "                nn.init.zeros_(mod.bias)\n",
        "    new_blocks.append(b)\n",
        "\n",
        "# Append to encoder_layers ModuleList (works for ModuleList or list-like)\n",
        "try:\n",
        "    # If ModuleList\n",
        "    for nb in new_blocks:\n",
        "        encoder_layers.append(nb)\n",
        "except Exception:\n",
        "    # If plain list, reassign\n",
        "    encoder_layers = list(encoder_layers) + new_blocks\n",
        "    # patch it back onto the backbone (if attribute name is 'encoder.layers' or 'blocks')\n",
        "    if hasattr(backbone, \"encoder\") and hasattr(backbone.encoder, \"layers\"):\n",
        "        backbone.encoder.layers = nn.ModuleList(encoder_layers)\n",
        "    elif hasattr(backbone, \"blocks\"):\n",
        "        backbone.blocks = nn.ModuleList(encoder_layers)\n",
        "    else:\n",
        "        raise RuntimeError(\"Couldn't set encoder layers back on backbone\")\n",
        "\n",
        "print(\"New encoder layer count:\", len(encoder_layers))\n"
      ],
      "metadata": {
        "id": "Vw1YtEZ8qoUe",
        "outputId": "9f180023-a042-4616-fc7c-510934b7f333",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing encoder layers: 12\n",
            "Cloning block at index 11 type: <class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
            "New encoder layer count: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: freeze first 9 layers, fine-tune last 6 (including newly added)\n",
        "freeze_until = 9  # freeze layers indices 0..8\n",
        "for i, layer in enumerate(encoder_layers):\n",
        "    requires = False if i < freeze_until else True\n",
        "    for p in layer.parameters():\n",
        "        p.requires_grad = requires\n",
        "print(\"Parameters frozen for layers < \", freeze_until)\n",
        "# Also ensure classification head params are trainable:\n",
        "for p in model.parameters():\n",
        "    if p.requires_grad:\n",
        "        pass\n",
        "# Print number of trainable params\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Trainable params: {trainable:,} / {total:,}\")\n"
      ],
      "metadata": {
        "id": "PI1GS-zIqyXF",
        "outputId": "01067efe-0fb8-44f7-b93a-326be3e6e148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters frozen for layers <  9\n",
            "Trainable params: 44,303,594 / 108,094,442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model state, export layer summary, zip outputs and expose download links\n",
        "import os, sys, zipfile\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from IPython.display import FileLink, display\n",
        "import json\n",
        "\n",
        "OUT_DIR = Path(\"/content/feature_outputs\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) Save model.state_dict (model should already be in memory from your previous cells)\n",
        "MODEL_OUT = OUT_DIR / \"model_with_extra_layers.pt\"\n",
        "try:\n",
        "    # prefer full state_dict to be safe (works even if model on CPU/GPU)\n",
        "    torch.save(model.state_dict(), str(MODEL_OUT))\n",
        "    print(\"Saved model state_dict to:\", MODEL_OUT)\n",
        "except Exception as e:\n",
        "    print(\"Failed to save model state_dict:\", e)\n",
        "    # try saving the entire model object as fallback\n",
        "    try:\n",
        "        torch.save(model, str(MODEL_OUT.with_suffix(\".fullmodel.pt\")))\n",
        "        print(\"Saved full model object as fallback:\", MODEL_OUT.with_suffix(\".fullmodel.pt\"))\n",
        "    except Exception as e2:\n",
        "        print(\"Failed to save full model object:\", e2)\n",
        "\n",
        "# 2) Write a layer summary file\n",
        "summary_path = OUT_DIR / \"encoder_layers_summary.txt\"\n",
        "try:\n",
        "    # attempt to inspect encoder_layers variable\n",
        "    enc = encoder_layers  # should exist from prior steps\n",
        "    with open(summary_path, \"w\") as f:\n",
        "        f.write(f\"Encoder layer count: {len(enc)}\\n\\n\")\n",
        "        for i, layer in enumerate(enc):\n",
        "            f.write(f\"Layer {i}: type={type(layer)}\\n\")\n",
        "            # list first-level submodules for quick glance\n",
        "            children = list(layer.named_children())\n",
        "            if children:\n",
        "                f.write(\"  submodules:\\n\")\n",
        "                for name, mod in children:\n",
        "                    f.write(f\"    - {name}: {type(mod)}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "    print(\"Wrote encoder layer summary to:\", summary_path)\n",
        "except Exception as e:\n",
        "    print(\"Failed to write layer summary (encoder_layers may not be in scope):\", e)\n",
        "\n",
        "# 3) Optionally include your original uploaded zip in the bundle if present\n",
        "orig_zip = Path(\"/mnt/data/Melanoma-Dermoscopic-Prognosis-main.zip\")\n",
        "include_orig = orig_zip.exists()\n",
        "if include_orig:\n",
        "    print(\"Found original uploaded zip at:\", orig_zip)\n",
        "else:\n",
        "    print(\"Original uploaded zip not found at /mnt/data/Melanoma-Dermoscopic-Prognosis-main.zip (that's okay).\")\n",
        "\n",
        "# 4) Create a zip bundle of outputs\n",
        "zip_path = OUT_DIR / \"exported_model_and_summary.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    if MODEL_OUT.exists():\n",
        "        zf.write(MODEL_OUT, MODEL_OUT.name)\n",
        "    if summary_path.exists():\n",
        "        zf.write(summary_path, summary_path.name)\n",
        "    # include patch grid images if present (helpful)\n",
        "    for p in OUT_DIR.glob(\"layer_*_patch_grid.png\"):\n",
        "        zf.write(p, p.name)\n",
        "    # include attention raw/avg if present\n",
        "    for p in OUT_DIR.glob(\"layer_*attn*.*\"):\n",
        "        zf.write(p, p.name)\n",
        "    if include_orig:\n",
        "        zf.write(orig_zip, orig_zip.name)\n",
        "\n",
        "print(\"Created zip:\", zip_path, \" (size: {:.2f} MB)\".format(zip_path.stat().st_size / (1024*1024)))\n",
        "\n",
        "# 5) Expose direct download links in Colab UI\n",
        "print(\"\\nLocal files you can download:\")\n",
        "print(\" - Model state_dict:\", MODEL_OUT)\n",
        "print(\" - Layer summary:\", summary_path)\n",
        "print(\" - Zip bundle:\", zip_path)\n",
        "\n",
        "# FileLink (clickable in notebook)\n",
        "print(\"\\nClick the links below to preview/download (Colab will open a preview):\")\n",
        "display(FileLink(str(MODEL_OUT)))\n",
        "display(FileLink(str(summary_path)))\n",
        "display(FileLink(str(zip_path)))\n",
        "\n",
        "# 6) Also offer browser download using google.colab.files (works for small/medium files)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"\\nIf you prefer immediate browser download, call files.download on the zip now.\")\n",
        "    # Uncomment the next line to trigger a direct browser download immediately:\n",
        "    # files.download(str(zip_path))\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# 7) Print the exact local paths (useful if you want to refer to them elsewhere)\n",
        "print(\"\\nExact local paths:\")\n",
        "print(\"MODEL_OUT =\", MODEL_OUT)\n",
        "print(\"SUMMARY   =\", summary_path)\n",
        "print(\"ZIP_FILE  =\", zip_path)\n"
      ],
      "metadata": {
        "id": "jAu0h6SurfdN",
        "outputId": "fa78dbcb-acf2-4593-de03-6d64ae1ce735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model state_dict to: /content/feature_outputs/model_with_extra_layers.pt\n",
            "Wrote encoder layer summary to: /content/feature_outputs/encoder_layers_summary.txt\n",
            "Original uploaded zip not found at /mnt/data/Melanoma-Dermoscopic-Prognosis-main.zip (that's okay).\n",
            "Created zip: /content/feature_outputs/exported_model_and_summary.zip  (size: 378.21 MB)\n",
            "\n",
            "Local files you can download:\n",
            " - Model state_dict: /content/feature_outputs/model_with_extra_layers.pt\n",
            " - Layer summary: /content/feature_outputs/encoder_layers_summary.txt\n",
            " - Zip bundle: /content/feature_outputs/exported_model_and_summary.zip\n",
            "\n",
            "Click the links below to preview/download (Colab will open a preview):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/feature_outputs/model_with_extra_layers.pt"
            ],
            "text/html": [
              "<a href='/content/feature_outputs/model_with_extra_layers.pt' target='_blank'>/content/feature_outputs/model_with_extra_layers.pt</a><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/feature_outputs/encoder_layers_summary.txt"
            ],
            "text/html": [
              "<a href='/content/feature_outputs/encoder_layers_summary.txt' target='_blank'>/content/feature_outputs/encoder_layers_summary.txt</a><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/feature_outputs/exported_model_and_summary.zip"
            ],
            "text/html": [
              "<a href='/content/feature_outputs/exported_model_and_summary.zip' target='_blank'>/content/feature_outputs/exported_model_and_summary.zip</a><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "If you prefer immediate browser download, call files.download on the zip now.\n",
            "\n",
            "Exact local paths:\n",
            "MODEL_OUT = /content/feature_outputs/model_with_extra_layers.pt\n",
            "SUMMARY   = /content/feature_outputs/encoder_layers_summary.txt\n",
            "ZIP_FILE  = /content/feature_outputs/exported_model_and_summary.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIDEVRVwmPrk"
      },
      "source": [
        "## Optional: Save Results to Google Drive\n",
        "\n",
        "After training, you can save the outputs to your Google Drive for later use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjUywDJ4mPrk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}